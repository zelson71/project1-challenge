{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing Libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### went to https://crashviewer.nhtsa.dot.gov/CrashAPI and got the list of states and built a dictionary off of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_id = {1:[\"Alabama\",\"AL\"],\n",
    "            2:[\"Alaska\",\"AK\"],\n",
    "            4:[\"Arizona\",\"AZ\"],\n",
    "            5:[\"Arkansas\",\"AR\"],\n",
    "            6:[\"California\",\"CA\"],\n",
    "            8:[\"Colorado\",\"CO\"],\n",
    "            9:[\"Conneticut\",\"CT\"],\n",
    "            10:[\"Delaware\", \"DE\"],\n",
    "            11:[\"District of Columbia\",\"DC\"],\n",
    "            12:[\"Florida\",\"FL\"],\n",
    "            13:[\"Georgia\", \"GA\"],\n",
    "            15:[\"Hawaii\",\"HI\"],\n",
    "            16:[\"Idaho\",\"ID\"],\n",
    "            17:[\"Illinois\",\"IL\"],\n",
    "            18:[\"Indiana\",\"IN\"],\n",
    "            19:[\"Iowa\", \"IA\"],\n",
    "            20:[\"Kansas\", \"KS\"],\n",
    "            21:[\"Kentucky\",\"KY\"],\n",
    "            22:[\"Louisiana\",\"LA\"],\n",
    "            23:[\"Maine\",\"ME\"],\n",
    "            24:[\"Maryland\",\"MD\"],\n",
    "            25:[\"Massachusetts\",\"MA\"],\n",
    "            26:[\"Michigan\",\"MI\"],\n",
    "            27:[\"Minnesota\",\"MN\"],\n",
    "            28:[\"Mississippi\",\"MS\"],\n",
    "            29:[\"Missouri\",\"MO\"],\n",
    "            30:[\"Montana\",\"MT\"],\n",
    "            31:[\"Nebraska\",\"NB\"],\n",
    "            32:[\"Nevada\",\"NV\"],\n",
    "            33:[\"New Hampshire\",\"NH\"],\n",
    "            34:[\"New Jersey\",\"NJ\"],\n",
    "            35:[\"New Mexico\",\"NM\"],\n",
    "            36:[\"New York\",\"NY\"],\n",
    "            37:[\"North Carolina\",\"NC\"],\n",
    "            38:[\"North Dakota\",\"ND\"],\n",
    "            39:[\"Ohio\",\"OH\"],\n",
    "            40:[\"Oklahoma\",\"OK\"],\n",
    "            41:[\"Oregon\",\"OR\"],\n",
    "            42:[\"Pennsylvania\",\"PA\"],\n",
    "            43:\"Puerto Rico\",\n",
    "            44:[\"Rhode Island\",\"RI\"],\n",
    "            45:[\"South Carolina\",\"SC\"],\n",
    "            46:[\"South Dakota\",\"SD\"],\n",
    "            47:[\"Tennessee\",\"TN\"],\n",
    "            48:[\"Texas\",\"TX\"],\n",
    "            49:[\"Utah\",\"UT\"],\n",
    "            50:[\"Vermont\",\"VT\"],\n",
    "            51:[\"Virginia\",\"VA\"],\n",
    "            52:\"Virgin Islands\",\n",
    "            53:[\"Washington\", \"WA\"],\n",
    "            54:[\"West Virginia\",\"WV\"],\n",
    "            55:[\"Wisconsin\",\"WI\"],\n",
    "            56:[\"Wyoming\",\"WY\"]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a while loop for user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By default there is\n",
      " ['6', '8', '12', '17', '36', '39', '42', '48'] \n",
      " ['California', 'Colorado', 'Florida', 'Illinois', 'New York', 'Ohio', 'Pennsylvania', 'Texas']\n"
     ]
    }
   ],
   "source": [
    "state_list=[\"6\",\"8\",\"12\",\"17\",\"36\",\"39\",\"42\",\"48\"]\n",
    "state_name_list = [\"California\",\"Colorado\", \"Florida\", \"Illinois\", \"New York\", \"Ohio\",\"Pennsylvania\",\"Texas\"]\n",
    "inquiry = str\n",
    "while inquiry != \"done\" or inquiry != \"\":\n",
    "    print(f\"By default there is\\n {state_list} \\n {state_name_list}\")\n",
    "    \n",
    "    inquiry = input(\"Please input the state you are interested in getting Data for by Name or code (ex : CO for Colorado). if you are done type done\")\n",
    "   \n",
    "    if inquiry == \"done\":\n",
    "                    break\n",
    "    else:\n",
    "                    for i in state_id:\n",
    "                        if inquiry == state_id[i][0] or inquiry == state_id[i][1]:\n",
    "                            state_num = i\n",
    "                            state_list.append(state_num)\n",
    "                            state_name_list.append(inquiry)\n",
    "                            print(f\"{inquiry} added\")\n",
    "                            clear_output()\n",
    "                    \n",
    "print(f\"You added {state_name_list} to the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect query results for selected states --> result is series of dictionaries, I think?\n",
    "url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/analytics/GetInjurySeverityCounts?\"\n",
    "FromYear = \"2008\"\n",
    "ToYear = \"2018\"\n",
    "Results2 = []\n",
    "for State in state_list:\n",
    "    query_url = url + \"fromCaseYear=\" + FromYear + \"&toCaseYear=\" + ToYear + \"&state=\" + State + \"&county=\" + \"&format=json\"\n",
    "    response = requests.get(query_url).json()\n",
    "    Results2.append(response[\"Results\"][0])\n",
    "    print(State)\n",
    "    pprint(Results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_Results = []\n",
    "for i in [i for i,x in enumerate(state_list)]:\n",
    "    State_Results.append(Results2[i])\n",
    "#State_Results\n",
    "\n",
    "State_dfs = []\n",
    "for state in State_Results:\n",
    "    df = pd.DataFrame(state)\n",
    "    State_dfs.append(df)\n",
    "#State_dfs\n",
    "\n",
    "# for i in [i for i,x in enumerate(state_list)]:\n",
    "#     merged = pd.concat([i],axis=0, join=\"outer\")\n",
    "\n",
    "# for state in State_dfs:\n",
    "#     merged = pd.concat([state[]],axis=0, join=\"outer\")\n",
    "#for state in [state for state,x in enumerate(State_dfs)]:\n",
    "    #merged = pd.concat([state[0],state],axis=0)\n",
    "\n",
    "# merged.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df from results of query for each state\n",
    "cali_df = pd.DataFrame(Results2[0])\n",
    "colo_df = pd.DataFrame(Results2[1])\n",
    "flor_df = pd.DataFrame(Results2[2])\n",
    "illi_df = pd.DataFrame(Results2[3])\n",
    "NY_df = pd.DataFrame(Results2[4])\n",
    "ohio_df = pd.DataFrame(Results2[5])\n",
    "penn_df = pd.DataFrame(Results2[6])\n",
    "tex_df = pd.DataFrame(Results2[7])\n",
    "\n",
    "# set column heading so can merge\n",
    "cali_df['State'] = \"California\"\n",
    "colo_df['State'] = \"Colorado\"\n",
    "flor_df['State'] = \"Florida\"\n",
    "illi_df['State'] = \"Illinois\"\n",
    "NY_df['State'] = \"New York\"\n",
    "ohio_df['State'] = \"Ohio\"\n",
    "penn_df['State'] = \"Pennsyvlania\"\n",
    "tex_df['State'] = \"Texas\"\n",
    "\n",
    "merged = pd.concat([cali_df,colo_df,flor_df,illi_df,NY_df,ohio_df,penn_df,tex_df],axis=0)\n",
    "\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert TotalFatalCounts to integer\n",
    "merged['TotalFatalCounts'] = merged['TotalFatalCounts'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group df by states\n",
    "grouped_states = merged.groupby('State')\n",
    "grouped_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot total fatal crashes by state over time\n",
    "fig = go.Figure()\n",
    "for states,group in grouped_states['State']:\n",
    "    year = merged.loc[merged[\"State\"] == states][\"CaseYear\"]\n",
    "    crashes = merged.loc[merged[\"State\"] == states][\"TotalFatalCounts\"]\n",
    "\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x=year, y=crashes,\n",
    "                             mode='lines',\n",
    "                             name=states))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MAU data for mobile app adoption, reindex\n",
    "MAU_data = pd.read_csv('MAU_data.csv')\n",
    "MAU_data = MAU_data.fillna(0)\n",
    "MAU_data_index = MAU_data.set_index('App')\n",
    "MAU_data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAU_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop years from crash data to ones overlapping with MAU data\n",
    "grouped_years = merged.groupby('CaseYear')\n",
    "crashes_per_year = grouped_years['TotalFatalCounts'].agg('sum')\n",
    "#crashes_per_year_trimmed = crashes_per_year.drop(['2018','2017','2016','2015'])\n",
    "crashes_per_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop years from MAU_data to match years in crash data\n",
    "MAU_data_trimmed = MAU_data_index.drop(['2002','2003','2004','2005','2006','2007','2008','2009','2019'],axis=1)\n",
    "\n",
    "# transpose data\n",
    "MAU_trim_trans = MAU_data_trimmed.transpose()\n",
    "MAU_trim_total = MAU_trim_trans['Total']\n",
    "\n",
    "# set type to float\n",
    "MAU_trim_total.astype('float').dtypes\n",
    "MAU_trim_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set x and y values for scatter plot\n",
    "x_values = MAU_trim_total\n",
    "y_values = crashes_per_year\n",
    "print(x_values)\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of MAUs of mobile apps vs. Fatal Crashes for 5 years (2010-2014)\n",
    "plt.scatter(x_values,y_values)\n",
    "plt.xlabel('MAUs')\n",
    "plt.ylabel('Fatal Crashes')\n",
    "plt.title('Fatal Crashes in 8 States vs. MAUs of Top Mobile Apps in the US, 2010-2018')\n",
    "(slope, intercept, rvalue, pvalue, stderr) = st.linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.annotate(line_eq,(3000000000,15500),fontsize=15,color=\"red\")\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and read smartphone adoption datafile\n",
    "phone_adoption_df = pd.read_csv('smartphone adoption.csv')\n",
    "\n",
    "#trim years to match crash data years\n",
    "phone_adoption_trim = phone_adoption_df.drop([9,10,11,12,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatterplot and regression line of smartphone users and crash fatalities\n",
    "x_values2 = phone_adoption_trim['number of smartphone users in US (millions)']\n",
    "y_values = crashes_per_year\n",
    "plt.scatter(x_values2,y_values)\n",
    "plt.title('Fatal Crashes in 8 States vs. Number of Smartphone Users in US, 2010-2018')\n",
    "plt.xlabel('number of smartphone users in US')\n",
    "plt.ylabel('Fatal Crashes')\n",
    "(slope, intercept, rvalue, pvalue, stderr) = st.linregress(x_values2, y_values)\n",
    "regress_values = x_values2 * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "plt.annotate(line_eq,(75,15500),fontsize=15,color=\"red\")\n",
    "plt.plot(x_values2,regress_values,\"r-\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
